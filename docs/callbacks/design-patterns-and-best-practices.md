# Design Patterns and Best Practices

## Design Patterns

Callbacks provide a versatile toolkit for enhancing agent behavior. Here are some common ways developers leverage them in the ADK, often combining different callback types:

 **ü§∫Guardrails & Policy Enforcement**

* **Pattern:** Use `before_model_callback` to inspect the `LlmRequest`'s contents (prompts). If the content violates a policy (e.g., contains profanity, asks for restricted information), return a predefined `LlmResponse` to block the request and prevent it from reaching the LLM. The callback can also update the `callback_context.state` to flag the violation.  
  * **Example:** The profanity checker example uses `before_model_callback` to scan text and returns a "No bad word allowed" `LlmResponse` if profanity is detected, while also setting `state['profanity_trigger'] = True`.


**ü§πDynamic State Management**

* **Pattern:** Use any of the callbacks to read from or write to `callback_context.state` (or `tool_context.state`). This allows the agent's behavior to adapt based on previous interactions or results stored in the state. State changes made via `state['key'] = value` are automatically tracked in `event.actions.state_delta`.  
  * **Example:** An `after_tool_callback` could extract a transaction ID from a tool's response and save it to `tool_context.state['last_transaction_id']` for later reference by another agent or tool. A `before_agent_callback` could check `state['user_preferences']` to tailor the agent's initial greeting. The `output_key` feature in `LlmAgent` implicitly uses state updates after the agent runs.


**ü™µLogging and Monitoring**

* **Pattern:** Implement callbacks at various lifecycle points to log information to an external system or standard output. This provides visibility into the agent's execution flow, decisions, LLM interactions, and tool usage.  
  * **Example:** Log messages like "Executing \- Before Agent Callback: Agent name \- weather\_agent" or "Executing \- After Tool Callback: Tool \- get\_weather, Response: ..." to track the execution flow.


**üì¶Caching**

* **Pattern:** Use `before_model_callback` or `before_tool_callback` to implement caching. Check if a response for a similar `LlmRequest` or tool call (`args`) exists in the `callback_context.state` or an external cache. If found, return the cached `LlmResponse` or result dictionary, respectively, to skip the actual LLM call or tool execution. If not found, proceed with the call and use the corresponding `after_model_callback` or `after_tool_callback` to store the result for future use.  
  * **Example:** A `before_tool_callback` for `get_weather` could generate a cache key based on the `city` argument, check `tool_context.state` for this key, and return the cached weather data if present.


**üîÅRequest/Response Modification**

* **Pattern:** Use `before_model_callback` to modify the `LlmRequest` before it's sent (e.g., adding context from `state` to the instructions). Use `after_model_callback` to modify the `LlmResponse` (e.g., formatting, censoring). Use `before_tool_callback` to adjust tool `args`. Use `after_tool_callback` to refine the `tool_response`.  
  * **Example:** A `before_model_callback` could append a "Respond in French" instruction to `llm_request.config.system_instruction` if `callback_context.state['language'] == 'fr'`. An `after_tool_callback` could convert a raw numerical result into a formatted string.


**‚ùìConditional Control Flow & Skipping Steps**

* **Pattern:** Leverage the ability of `before_agent_callback`, `before_model_callback`, and `before_tool_callback` to return a value (`Content`, `LlmResponse`, or `dict` respectively). This effectively skips the subsequent standard operation (agent run, LLM call, or tool execution).  
  * **Example:** A `before_agent_callback` might check `state['user_authenticated']`; if `False`, it returns a `Content` object asking the user to log in, skipping the agent's main logic.


**‚öíÔ∏èTool-Specific Actions (Authentication & Summarization Control)**

* **Pattern:** Use `ToolContext` within tool callbacks. `before_tool_callback` can call `tool_context.request_credential()` to initiate an authentication flow if needed. Any tool callback can set `tool_context.actions.skip_summarization = True` if the tool's raw output should be sent back to the user/LLM without an intermediate summarization step by the model (as seen in `get_user_choice_tool` and `AgentTool`).  
  * **Example:** A tool interacting with a protected API might call `request_credential` in its `before_tool_callback` if `get_auth_response()` is empty.


**üìÑArtifact Handling**

* **Pattern:** Use `callback_context.save_artifact` or `tool_context.save_artifact` within any callback to store data (like files generated by a tool or intermediate LLM reasoning steps) associated with the session. Use `load_artifact` to retrieve previously saved artifacts. Changes are tracked in `event.actions.artifact_delta`.  
  * **Example:** An `after_tool_callback` for a report-generating tool could save the generated report PDF using `save_artifact`.

## Best Practices

Follow these guidelines for effective and maintainable callbacks:

**Keep Callbacks Focused:** Design callbacks for a single, clear task (e.g., logging or validation), avoiding overly complex functions.

**Mind Performance:** Callbacks run synchronously. Avoid slow or blocking operations (like heavy I/O) to prevent halting the agent. Offload work if necessary, but be mindful of added complexity.

**Handle Errors:** Use `try...except` within callbacks. Gracefully handle exceptions to prevent crashing the agent invocation and log errors gracefully and decide whether the agent should attempt to continue or halt.

**Manage State Carefully:** Be deliberate when modifying state via `callback_context.state` or `tool_context.state`. Understand that these changes are immediately visible to subsequent operations within the *same* invocation and will be persisted by the `SessionService` at the end of the event processing. Avoid unintended side effects by carefully managing state keys and values. Use distinct state prefixes like `State.APP_PREFIX`, `State.USER_PREFIX`, `State.TEMP_PREFIX` where appropriate.

**Consider Idempotency:** If a callback has external side effects (e.g., API calls), design it to be idempotent to handle potential retries safely.

**Test Thoroughly:** Unit test callbacks with mock contexts and integration test the full agent flow with callbacks enabled.

**Ensure Clarity:** Use descriptive function names and write clear docstrings explaining the callback's purpose, timing, and side effects (especially state changes).

**Use Correct Context:** Employ CallbackContext for agent/LLM events and ToolContext for tool events to access relevant information.
